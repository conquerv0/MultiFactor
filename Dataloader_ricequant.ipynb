{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rqdatac as rq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pathos\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a8b99",
   "metadata": {},
   "source": [
    "TODO: Refactor this into a class if needed in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5497d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use rq_crendential.json to fill out Ricequant credentials\n",
    "# WARNING: MAKE SURE rq_crendential.json ARE NOT COMMITTED TO GITHUB\n",
    "CRED_FILE = './rq_credential.json'\n",
    "with open(CRED_FILE) as file:\n",
    "    rq_cred = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af6041",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "RQ_USER, RQ_PASS = rq_cred['user'], rq_cred['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e228e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def rq_initialize(): \n",
    "    rq.init(RQ_USER, RQ_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986cf0f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def normalize_code(symbol, pre_close=None):\n",
    "    \"\"\"\n",
    "    归一化证券代码\n",
    "\n",
    "    :param code 如000001\n",
    "    :return 证券代码的全称 如000001.XSHE\n",
    "    \"\"\"\n",
    "    XSHG = 'XSHG'\n",
    "    SSE = 'XSHG'\n",
    "    SH = 'XSHG'\n",
    "    XSHE = 'XSHE'\n",
    "    SZ = 'XSHE'\n",
    "    SZE = 'XSHE'\n",
    "    if (not isinstance(symbol, str)):\n",
    "        return symbol\n",
    "\n",
    "    symbol = symbol.upper()\n",
    "    if (symbol.startswith('SZ') and (len(symbol) == 8)):\n",
    "        ret_normalize_code = '{}.{}'.format(symbol[2:8],SZ)\n",
    "    elif (symbol.startswith('SH') and (len(symbol) == 8)):\n",
    "        ret_normalize_code = '{}.{}'.format(symbol[2:8], SH)\n",
    "    elif (symbol.startswith('00') and (len(symbol) == 6)):\n",
    "        if ((pre_close is not None) and (pre_close > 2000)):\n",
    "            # 推断是上证指数\n",
    "            ret_normalize_code = '{}.{}'.format(symbol, SH)\n",
    "        else:\n",
    "            ret_normalize_code = '{}.{}'.format(symbol, SZ)\n",
    "    elif ((symbol.startswith('399') or symbol.startswith('159') or \\\n",
    "        symbol.startswith('150')) and (len(symbol) == 6)):\n",
    "        ret_normalize_code = '{}.{}'.format(symbol, SH)\n",
    "    elif ((len(symbol) == 6) and (symbol.startswith('399') or \\\n",
    "        symbol.startswith('159') or symbol.startswith('150') or \\\n",
    "        symbol.startswith('16') or symbol.startswith('184801') or \\\n",
    "        symbol.startswith('201872'))):\n",
    "        ret_normalize_code = '{}.{}'.format(symbol, SZ)\n",
    "    elif ((len(symbol) == 6) and (symbol.startswith('50') or \\\n",
    "        symbol.startswith('51') or symbol.startswith('60') or \\\n",
    "        symbol.startswith('688') or symbol.startswith('900') or \\\n",
    "        (symbol == '751038'))):\n",
    "        ret_normalize_code = '{}.{}'.format(symbol, SH)\n",
    "    elif ((len(symbol) == 6) and (symbol[:3] in ['000', '001', '002', \n",
    "                                                 '200', '300'])):\n",
    "        ret_normalize_code = '{}.{}'.format(symbol, SZ)\n",
    "    else:\n",
    "        print(symbol)\n",
    "        ret_normalize_code = symbol\n",
    "\n",
    "    return ret_normalize_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb7fd4e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "stock_names = [dl.normalize_code(csv_name.split(\".\")[0]) for csv_name in csv_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a672b27",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_basic_info():\n",
    "    #parrallel computing speeds up the process x10 times\n",
    "    #returns a list containing many dataframes, each corresponding to a stock\n",
    "\n",
    "    def get_df(name):\n",
    "        return pd.read_csv(stock_path+name)\n",
    "        # return pd.read_csv(stock_path+name).set_index(['date'])\n",
    "\n",
    "    with pathos.multiprocessing.ProcessPool(pathos.helpers.cpu_count()) as pool:\n",
    "        results = pool.map(get_df, csv_names)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a89d57",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_price_data(col='close'): \n",
    "    #concatenate the price column from each csv\n",
    "    results = load_basic_info()\n",
    "    price_data = pd.concat([result[col] for result in results], axis=1)\n",
    "    stock_names = [dl.normalize_code(csv_name.split(\".\")[0]) for csv_name in csv_names]\n",
    "    price_data.columns = stock_names\n",
    "    return price_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07fa44a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_industry_mapping():\n",
    "    if not os.path.exists(\"./Data/raw_data/industry_mapping.h5\"):\n",
    "        indus_to_stock = {industry: rq.industry(industry) for industry in industry_codes}\n",
    "        stock_to_indus = {}\n",
    "        for indus, stock_names in indus_to_stock.items():\n",
    "            for stock in stock_names:\n",
    "                if stock in stock_to_indus: print(f\"{stock} repeated!\")\n",
    "                stock_to_indus[stock] = indus\n",
    "        df_indus_mapping = pd.Series(stock_to_indus, name='secon_indus_code').to_frame()\n",
    "        df_indus_mapping['pri_indus_code'] = df_indus_mapping['secon_indus_code'].str[0]\n",
    "        df_indus_mapping.to_hdf(\"./Data/raw_data/industry_mapping.h5\", key='industry_mapping')\n",
    "    df_indus_mapping = pd.read_hdf(\"./Data/raw_data/industry_mapping.h5\", key='industry_mapping')\n",
    "    return df_indus_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8eac2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_st_data(stock_names) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    stock_names: an iterable of stock names\n",
    "    returns: a multindex(date and stockname) dataframe indicating whether a stock is an ST stock on a given date\n",
    "    \"\"\"\n",
    "    #if the dataframe is not stored in the local folder then we fetch it first\n",
    "    if not os.path.exists('./Data/raw_data/is_st.h5'):\n",
    "        df_is_st = rq.is_st_stock(stock_names, START_DATE, END_DATE).stack()\n",
    "        df_is_st.to_hdf('./Data/raw_data/is_st.h5', key='is_st')\n",
    "    #load the dataframe\n",
    "    df_is_st = pd.read_hdf('./Data/raw_data/is_st.h5', key='is_st')\n",
    "    df_is_st = df_is_st[df_is_st.index.get_level_values(1).isin(stock_names)]\n",
    "    return df_is_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6862eb4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_suspended_data(stock_names):\n",
    "    \"\"\"\n",
    "    stock_names: an iterable of stock names\n",
    "    returns: a multindex(date and stockname) dataframe indicating whether a stock is a suspended stock on a given date\n",
    "    \"\"\"\n",
    "    #if the dataframe is not stored in the local folder then we fetch it first\n",
    "    if not os.path.exists('./Data/raw_data/is_suspended.h5'):\n",
    "        df_is_suspended = rq.is_suspended_stock(stock_names, START_DATE, END_DATE).stack()\n",
    "        df_is_suspended.to_hdf('./Data/raw_data/is_suspended.h5', key='is_suspended')\n",
    "    #load the dataframe\n",
    "    df_is_suspended = pd.read_hdf('./Data/raw_data/is_suspended.h5', key='is_suspended')\n",
    "    df_is_suspended = df_is_suspended[df_is_suspended.index.get_level_values(1).isin(stock_names)]\n",
    "    return df_is_suspended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae2a26",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_listed_dates():\n",
    "    #get the listed date for each stock\n",
    "    #the listed date of a stock is the earliest date in the stock's csv under ./Data/stock_data\n",
    "    if not os.path.exists(\"./Data/raw_data/listed_dates\"):\n",
    "        results = load_basic_info()\n",
    "        listed_dates = [result.index.min() for result in results]\n",
    "        listed_dates = pd.Series(dict(zip(stock_names, listed_dates)))\n",
    "        listed_dates.to_hdf(\"./Data/raw_data/listed_dates\", key='listed_dates')\n",
    "    listed_dates = pd.read_hdf(\"./Data/raw_data/listed_dates\", key='listed_dates')\n",
    "    return listed_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6570e2da",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_factor_data(factor: str) -> pd.DataFrame:\n",
    "    ''' Something something\n",
    "    '''\n",
    "    try:\n",
    "        factor_data = pd.read_hdf(DATAPATH + f'factor/{factor}.h5')\n",
    "    except:\n",
    "        print(f'{factor}.h5 not found')\n",
    "            \n",
    "    return factor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fac4e7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def download_factor_data(stock_names: np.array, factor_name: str, startdate: str, enddate: str) -> None:\n",
    "    if not os.path.exists(f\"./Data/factor/{factor_name}.h5\"):\n",
    "        factor_frame = rq.get_factor(stock_names, factor_name, startdate, enddate)\n",
    "        factor_frame.to_hdf(DATAPATH + f'factor/{factor_name}.h5', key='factor')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
